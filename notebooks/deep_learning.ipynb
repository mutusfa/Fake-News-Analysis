{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuATy2Dt9rUM",
        "outputId": "d9ef43ff-cc31-47dc-951a-4e5a21d16ec0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/mutusfa/Fake-News-Analysis scikit-learn-intelex huggingface_hub pytorch_lightning transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4vuljgCX4-eo",
        "outputId": "b1542a3f-e2c9-4c42-f6d9-4825242de7de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/mutusfa/Fake-News-Analysis\n",
            "  Cloning https://github.com/mutusfa/Fake-News-Analysis to /tmp/pip-req-build-b8gg46ar\n",
            "  Running command git clone -q https://github.com/mutusfa/Fake-News-Analysis /tmp/pip-req-build-b8gg46ar\n",
            "Collecting scikit-learn-intelex\n",
            "  Downloading scikit_learn_intelex-2021.5.3-py37-none-manylinux1_x86_64.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 8.1 MB/s \n",
            "\u001b[?25hCollecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.5.10-py3-none-any.whl (527 kB)\n",
            "\u001b[K     |████████████████████████████████| 527 kB 70.1 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 62.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-intelex) (1.0.2)\n",
            "Collecting daal4py==2021.5.3\n",
            "  Downloading daal4py-2021.5.3-py37-none-manylinux1_x86_64.whl (22.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.5 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from daal4py==2021.5.3->scikit-learn-intelex) (1.19.5)\n",
            "Collecting daal==2021.5.3\n",
            "  Downloading daal-2021.5.3-py2.py3-none-manylinux1_x86_64.whl (284.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 284.3 MB 2.3 kB/s \n",
            "\u001b[?25hCollecting tbb==2021.*\n",
            "  Downloading tbb-2021.5.1-py2.py3-none-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 45.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.4.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.4.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.10.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (21.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface_hub) (3.0.7)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 73.3 MB/s \n",
            "\u001b[?25hCollecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 60.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.7.0)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.7.2-py3-none-any.whl (397 kB)\n",
            "\u001b[K     |████████████████████████████████| 397 kB 60.5 MB/s \n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 71.3 MB/s \n",
            "\u001b[?25hCollecting setuptools==59.5.0\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[K     |████████████████████████████████| 952 kB 53.4 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: torch>=1.7.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.10.0+cu111)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 52.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.43.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface_hub) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.2.0)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 47.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.11)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 72.5 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 73.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Building wheels for collected packages: jjuoda-dl.4, future\n",
            "  Building wheel for jjuoda-dl.4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jjuoda-dl.4: filename=jjuoda_dl.4-0.0.1-py3-none-any.whl size=3106 sha256=659c4e73bb0b9a0c1346033727359c16bf8fa8a28eb37bc04bc8091d3c028b00\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-un0lp03m/wheels/8f/48/69/072e2f6ae465cf727fe2a9a38d41b7ef1564525d54866fb8eb\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=ff030a338dcada3b3396b1f7e734ac84877224a333aac17fcae1264eee6782d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built jjuoda-dl.4 future\n",
            "Installing collected packages: setuptools, multidict, frozenlist, yarl, tbb, asynctest, async-timeout, aiosignal, pyyaml, pyDeprecate, fsspec, daal, aiohttp, torchmetrics, tokenizers, sacremoses, huggingface-hub, future, daal4py, transformers, scikit-learn-intelex, pytorch-lightning, jjuoda-dl.4\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 daal-2021.5.3 daal4py-2021.5.3 frozenlist-1.3.0 fsspec-2022.1.0 future-0.18.2 huggingface-hub-0.4.0 jjuoda-dl.4-0.0.1 multidict-6.0.2 pyDeprecate-0.3.1 pytorch-lightning-1.5.10 pyyaml-6.0 sacremoses-0.0.47 scikit-learn-intelex-2021.5.3 setuptools-59.5.0 tbb-2021.5.1 tokenizers-0.11.4 torchmetrics-0.7.2 transformers-4.16.2 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Monkey patch for runtime in colab\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import jjuoda_dl4.utils\n",
        "\n",
        "# the function that reads articles will default to old path but whatever\n",
        "jjuoda_dl4.utils.BASE_DATA_DIR = Path(\"/content/drive/MyDrive/Fake News Analysis/Data\")\n",
        "jjuoda_dl4.utils.BASE_MODEL_DIR = Path(\"/content/drive/MyDrive/Fake News Analysis/Models\")"
      ],
      "metadata": {
        "id": "QXJ-kRt89v5K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoSp_U0H28V4",
        "outputId": "80ee1fdb-6073-4e99-9ecd-236ac92ba824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearnex import patch_sklearn\n",
        "\n",
        "patch_sklearn()\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytorch_lightning as pl\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchmetrics.functional import auroc\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "\n",
        "from jjuoda_dl4 import utils\n",
        "from jjuoda_dl4.utils import BASE_DATA_DIR, BASE_MODEL_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "20EOiwzK28V-"
      },
      "outputs": [],
      "source": [
        "nela_gt_2018_articles_df = pd.read_csv(\n",
        "    BASE_DATA_DIR / \"interim/nela-gt-2018-articles-with-text.csv\", index_col=0\n",
        ")\n",
        "nela_gt_2018_scores_df = pd.read_csv(\n",
        "    BASE_DATA_DIR / \"interim/nela-gt-2018-scores.csv\", index_col=0\n",
        ")\n",
        "nela_gt_2018_articles_df.dropna(subset=[\"title\", \"text\"], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6Z5XTcP28WA"
      },
      "source": [
        "### AutoNLP from HuggingFace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su-s2Y6O28WB"
      },
      "source": [
        "#### DataModules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LH-Z_dr828WB"
      },
      "outputs": [],
      "source": [
        "# I tried using hugging face api, my machine runs out of ram, so we'll use pytorch lightning\n",
        "\n",
        "\n",
        "class AutoNLPNELADataset(Dataset):\n",
        "    \"\"\"Recreates processeing I did for AutoNLP on nela gt 2018 data.\"\"\"\n",
        "\n",
        "    def __init__(self, articles_df, tokenizer, root_dir=BASE_DATA_DIR):\n",
        "        self.articles_df = articles_df\n",
        "        self.root_dir = root_dir\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.articles_df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        article = self.articles_df.iloc[index]\n",
        "        with open(self.root_dir / article.path, \"r\") as f:\n",
        "            text = f.read().replace(\"\\n\", \" \")\n",
        "        text = \"<TITLE> \" + article.title + \" </TITLE> \" + text\n",
        "        inputs = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=\"max_length\",\n",
        "            truncation=\"longest_first\",\n",
        "        )\n",
        "        return {\n",
        "            \"model_inputs\": inputs,\n",
        "            \"source_score\": article.source_score,\n",
        "            \"is_fake\": article.source_score < 0,\n",
        "        }\n",
        "\n",
        "\n",
        "class AutoNLPNelaDataModule(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        articles_df,\n",
        "        tokenizer,\n",
        "        root_dir=BASE_DATA_DIR,\n",
        "        batch_size=32,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.articles_df = articles_df\n",
        "        self.root_dir = root_dir\n",
        "        self.tokenizer = tokenizer\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def prepare_data(self):\n",
        "        self.train_dataset = AutoNLPNELADataset(\n",
        "            self.articles_df[self.articles_df.split == \"train\"],\n",
        "            self.tokenizer,\n",
        "            self.root_dir,\n",
        "        )\n",
        "        self.val_dataset = AutoNLPNELADataset(\n",
        "            self.articles_df[self.articles_df.split == \"val\"],\n",
        "            self.tokenizer,\n",
        "            self.root_dir,\n",
        "        )\n",
        "        self.test_dataset = AutoNLPNELADataset(\n",
        "            self.articles_df[self.articles_df.split == \"test\"],\n",
        "            self.tokenizer,\n",
        "            self.root_dir,\n",
        "        )\n",
        "        self.pred_dataset = AutoNLPNELADataset(\n",
        "            self.articles_df[self.articles_df.split == \"pred\"],\n",
        "            self.tokenizer,\n",
        "            self.root_dir,\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4\n",
        "        )\n",
        "\n",
        "    def pred_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.pred_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SaWmuqZ28WE"
      },
      "source": [
        "I just hope to get quick results that I can look at and refine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387,
          "referenced_widgets": [
            "fd04ed39cfab41c0894795cb5fb628ca",
            "9686f94ee4ef4e8fa80ea72b7dee69b2",
            "cd7c7a2440fd487d8143e92aa2b7ae61",
            "31ab667aefa045c3b1ff00261b801672",
            "42d64507625d41fd95086e340425d69a",
            "4dcec957b10b406d9a2ee305b9cce738",
            "92709468e7164425967362ce666e63fc",
            "a1d7512e03f74f7798c9d335efb562a9",
            "4a96b39391f94c8a82c209b6f1c2b53d",
            "11c97861f31e44c285abb27a5fb962b2",
            "66d238e972f34db88e4aff730282a5b4",
            "d3f1afbcaeff415aa9067e6787e21262",
            "b68bab8ce00042f1856c59c8a8acff9e",
            "f9fb376540c74fe29541ce953b2b7081",
            "158e936416a2495aa5cfb0e593155e54",
            "28aad1c0dba3480389843dc364b8cfc4",
            "d7b3cb2d8d2944028859023b9326e02f"
          ]
        },
        "id": "iC8mVOIG28WE",
        "outputId": "67768c42-b2d6-432c-cb27-96d66c7ac373"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd04ed39cfab41c0894795cb5fb628ca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center>\\n<img src=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nShU4Y4U28WF"
      },
      "outputs": [],
      "source": [
        "model_names = [\n",
        "    \"mutusfa/autonlp-Fake_News_Analysis-528914957\",\n",
        "    \"mutusfa/autonlp-Fake_News_Analysis-528914958\",\n",
        "    \"mutusfa/autonlp-Fake_News_Analysis-528914959\",\n",
        "    \"mutusfa/autonlp-Fake_News_Analysis-528914960\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qNdb_3PG28WG"
      },
      "outputs": [],
      "source": [
        "y = np.random.randn(1000)\n",
        "x = np.random.randint(0, 10, size=(1000,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "r2iJiiDw28WG"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def plot_predictions(articles_df, model_name):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name, use_auth_token=True\n",
        "    )\n",
        "    model.to(device)\n",
        "\n",
        "    data_module = AutoNLPNelaDataModule(articles_df, tokenizer, batch_size=64)\n",
        "    data_module.prepare_data()\n",
        "    dataloaders = [data_module.pred_dataloader()]\n",
        "\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    source_scores = []\n",
        "    with torch.no_grad():\n",
        "        for dataloader in dataloaders:\n",
        "            for batch in dataloader:\n",
        "                # I'm not sure why do I get 32 * 1 * 512 tensors\n",
        "                for k in batch[\"model_inputs\"]:\n",
        "                    batch[\"model_inputs\"][k] = (\n",
        "                        batch[\"model_inputs\"][k].squeeze(1).to(device)\n",
        "                    )\n",
        "                preds.extend(\n",
        "                    sigmoid(model(**batch[\"model_inputs\"]).logits[:, 1].cpu().numpy())\n",
        "                )\n",
        "                source_scores.extend(batch[\"source_score\"].numpy())\n",
        "\n",
        "    plt.figure()\n",
        "    ax = sns.regplot(\n",
        "        x=source_scores,\n",
        "        y=preds,\n",
        "        x_jitter=0.1,\n",
        "        line_kws={\"color\": \"#859900\"},\n",
        "        scatter_kws={\"alpha\": 0.5},\n",
        "    )\n",
        "    plt.suptitle(model_name)\n",
        "    plt.ylabel(\"Predicted probability of being fake\")\n",
        "    plt.xlabel(\"Source score\")\n",
        "    plt.savefig(\n",
        "        BASE_DATA_DIR / f\"processed/{model_name.replace('/', '_')}_reg_predictions.png\"\n",
        "    )\n",
        "\n",
        "    return preds, source_scores\n",
        "\n",
        "\n",
        "# for model_name in model_names:\n",
        "#     preds, scores = plot_predictions(\n",
        "#         nela_gt_2018_articles_df[nela_gt_2018_articles_df.split == \"pred\"].sample(\n",
        "#             n=1000, random_state=42\n",
        "#         ),\n",
        "#         model_name,\n",
        "#     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xPZUg5r28WH"
      },
      "source": [
        "These models achieved much better auc than knn models (all above .95 versus .86 I had with knn) on their validation set. The only problem - training set was quite imbalanced and I have changed both training set and validation set, so they are not directly comparable.\n",
        "\n",
        "Looking at the data both models didn't see, we see interesting differences.\n",
        "1. KNNs predict most news as having high probability of being fake news, while AutoNLP models predict most news as having low probability of being fake news.\n",
        "1. It also seems that AutoNLP models generalize pretty badly - some can't distinguish between sources with -1 score and sources with 1 score. I guess I have to check if I can distinguish that, but knns seem to be able to do that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq2UQZCw28WH"
      },
      "source": [
        "Let's try tuning a few models and see if I can get better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMXWfhQW28WH"
      },
      "source": [
        "### My work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "AAFa3Odq28WH"
      },
      "outputs": [],
      "source": [
        "class NELADataset(Dataset):\n",
        "    def __init__(self, articles_df, tokenizer, root_dir=BASE_DATA_DIR):\n",
        "        self.articles_df = articles_df\n",
        "        self.root_dir = root_dir\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.articles_df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        article = self.articles_df.iloc[index]\n",
        "        if \"text\" in article.keys():\n",
        "            text = article[\"text\"]\n",
        "        else:\n",
        "            with open(self.root_dir / article.path, \"r\") as f:\n",
        "                text = f.read()\n",
        "        inputs = self.tokenizer(\n",
        "            article.title,\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=\"max_length\",\n",
        "            truncation=\"longest_first\",\n",
        "        )\n",
        "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n",
        "        inputs[\"labels\"] = torch.tensor(article.source_score < 0, dtype=int)\n",
        "        return inputs\n",
        "\n",
        "\n",
        "class NelaDataModule(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        articles_df,\n",
        "        tokenizer,\n",
        "        root_dir=BASE_DATA_DIR,\n",
        "        batch_size=32,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.articles_df = articles_df\n",
        "        self.root_dir = root_dir\n",
        "        self.tokenizer = tokenizer\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def prepare_data(self):\n",
        "        self.train_dataset = NELADataset(\n",
        "            self.articles_df[self.articles_df.split == \"train\"],\n",
        "            self.tokenizer,\n",
        "            self.root_dir,\n",
        "        )\n",
        "        self.val_dataset = NELADataset(\n",
        "            self.articles_df[self.articles_df.split == \"val\"],\n",
        "            self.tokenizer,\n",
        "            self.root_dir,\n",
        "        )\n",
        "        self.test_dataset = NELADataset(\n",
        "            self.articles_df[self.articles_df.split == \"test\"],\n",
        "            self.tokenizer,\n",
        "            self.root_dir,\n",
        "        )\n",
        "        self.pred_dataset = NELADataset(\n",
        "            self.articles_df[self.articles_df.split == \"pred\"],\n",
        "            self.tokenizer,\n",
        "            self.root_dir,\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=2\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2\n",
        "        )\n",
        "\n",
        "    def pred_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.pred_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2fSZ4JL28WI",
        "outputId": "1f0f4cd5-1c01-4d38-c9b4-adea8a5bf0ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = transformers.DistilBertTokenizerFast.from_pretrained(\n",
        "    \"distilbert-base-uncased\"\n",
        ")\n",
        "model = transformers.DistilBertForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "yoq4QylY28WI"
      },
      "outputs": [],
      "source": [
        "nela_gt_2018_data_module = NelaDataModule(nela_gt_2018_articles_df, tokenizer)\n",
        "nela_gt_2018_data_module.prepare_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "jkzRQD4U28WJ"
      },
      "outputs": [],
      "source": [
        "class NelaModel(pl.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def backbone_grad(self, value):\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = value\n",
        "        for param in self.model.pre_classifier.parameters():\n",
        "          param.requires_grad = True\n",
        "        for param in self.model.classifier.parameters():\n",
        "          param.requires_grad = True\n",
        "\n",
        "    def forward(self, **model_inputs):\n",
        "        return self.model(**model_inputs)\n",
        "\n",
        "    def _shared_step(self, batch, batch_idx):\n",
        "        return self.model(**batch)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        results = self._shared_step(batch, batch_idx)\n",
        "        self.log(\"train_loss\", results.loss.detach())\n",
        "        return results\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        results = self._shared_step(batch, batch_idx)\n",
        "        self.log(\"val_loss\", results.loss.detach())\n",
        "        self.log(\"val_auc\", auroc(torch.sigmoid(results.logits.detach()[:, 1]), batch[\"labels\"], num_classes=2))\n",
        "        return results\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(\n",
        "            params=[p for p in self.parameters() if p.requires_grad],\n",
        "            lr=self.learning_rate,\n",
        "        )\n",
        "\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, patience=3\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": scheduler,\n",
        "            \"monitor\": \"val_loss\",\n",
        "        }\n",
        "\n",
        "\n",
        "nela_model = NelaModel(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449,
          "referenced_widgets": [
            "bf50bc4190b94a21aea94f2c19bdd023",
            "a0d4f5d44d224c929d0be260e0ca5151",
            "52df6d0202484dbd9a55717c12d09b44",
            "3234bee7447848f59229bd1392d8dba6",
            "6bc4d5719a674ec78e7ec3af21b12c2e",
            "50665e6d5bcc45c7a8c3ea58a5a4af21",
            "860c47baa44845c1ac315ea623ab36fb",
            "1dbca1e50fa14a92b29dfa4abc9eb8cd",
            "e131534c45d54723b871225b9785daf7",
            "6c1cc5159e7b4ca1b88ae5879c3edaa9",
            "2056e6f329904e42a4c82691dfdace38",
            "3f43cff606814637bb70a74e22b22ce2",
            "b15753e3ebf24cf1b09eba1c331d613c",
            "707a090cfcbf4ba588033c3e54de7a34",
            "2a29c29f98684c27821b11a1ba999cd2",
            "004cc4dd6e4a4564b26b0f71323fc664",
            "9a2d340f7fa24bafa41d81d7241d9f56",
            "68b7b8c6481c4841b40a67de3105bd68",
            "6387035d863749559293b535412c5bff",
            "6498ae933d24428b8361b37c6f6e44ab",
            "641afd6aeadf4f2ebbe56c35fb95b864",
            "32ec14afd6dd4bc983ec6f9b4e4105c7"
          ]
        },
        "id": "tzmf7Vrt28WJ",
        "outputId": "9152b93c-980b-4216-caf9-2890261db618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type                                | Params\n",
            "--------------------------------------------------------------\n",
            "0 | model | DistilBertForSequenceClassification | 67.0 M\n",
            "--------------------------------------------------------------\n",
            "592 K     Trainable params\n",
            "66.4 M    Non-trainable params\n",
            "67.0 M    Total params\n",
            "267.820   Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf50bc4190b94a21aea94f2c19bdd023",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f43cff606814637bb70a74e22b22ce2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/closure.py:36: LightningDeprecationWarning: One of the returned values {'logits'} has a `grad_fn`. We will detach it automatically but this behaviour will change in v1.6. Please detach it manually: `return {'loss': ..., 'something': something.detach()}`\n",
            "  f\"One of the returned values {set(extra.keys())} has a `grad_fn`. We will detach it automatically\"\n"
          ]
        }
      ],
      "source": [
        "nela_model.backbone_grad(False)\n",
        "nela_model.learning_rate = 1e-3\n",
        "trainer = pl.Trainer(\n",
        "    min_epochs=3,\n",
        "    gpus=1,                     \n",
        "    callbacks=[\n",
        "        pl.callbacks.EarlyStopping(\n",
        "            patience=5, min_delta=0.0001, monitor=\"val_loss/dataloader_idx_1\"\n",
        "        ),\n",
        "        pl.callbacks.LearningRateMonitor(logging_interval=\"step\", log_momentum=False),\n",
        "        pl.callbacks.model_checkpoint.ModelCheckpoint(\n",
        "            BASE_DATA_DIR / \"best\",\n",
        "            filename='{epoch}-{val_loss:.2f}-{val_auc:.2f}',\n",
        "            monitor=\"val_loss\",\n",
        "        )\n",
        "    ],\n",
        "    default_root_dir=BASE_MODEL_DIR,\n",
        ")\n",
        "trainer.fit(nela_model, nela_gt_2018_data_module)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nela_model.backbone_grad(True)\n",
        "nela_model.learning_rate = 1e-5\n",
        "trainer = pl.Trainer(\n",
        "    min_epochs=3,\n",
        "    gpus=1,                     \n",
        "    callbacks=[\n",
        "        pl.callbacks.EarlyStopping(\n",
        "            patience=5, min_delta=0.0001, monitor=\"val_loss/dataloader_idx_1\"\n",
        "        ),\n",
        "        pl.callbacks.LearningRateMonitor(logging_interval=\"step\", log_momentum=False),\n",
        "        pl.callbacks.model_checkpoint.ModelCheckpoint(\n",
        "            BASE_DATA_DIR / \"best\",\n",
        "            filename='{epoch}-{val_loss:.2f}-{val_auc:.2f}',\n",
        "            monitor=\"val_loss\",\n",
        "        )\n",
        "    ],\n",
        "    default_root_dir=BASE_MODEL_DIR,\n",
        ")\n",
        "trainer.fit(nela_model, nela_gt_2018_data_module)"
      ],
      "metadata": {
        "id": "RH6Z5eD39WuU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "5a7d5478afe2248c49abfa1219649289765da77ad68068bfc5af38a5747c85f1"
    },
    "kernelspec": {
      "display_name": "jjuoda-DL.4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "deep_learning.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fd04ed39cfab41c0894795cb5fb628ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9686f94ee4ef4e8fa80ea72b7dee69b2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cd7c7a2440fd487d8143e92aa2b7ae61",
              "IPY_MODEL_31ab667aefa045c3b1ff00261b801672",
              "IPY_MODEL_42d64507625d41fd95086e340425d69a",
              "IPY_MODEL_4dcec957b10b406d9a2ee305b9cce738",
              "IPY_MODEL_92709468e7164425967362ce666e63fc"
            ]
          }
        },
        "9686f94ee4ef4e8fa80ea72b7dee69b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "column",
            "width": "50%",
            "min_width": null,
            "border": null,
            "align_items": "center",
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "flex",
            "left": null
          }
        },
        "cd7c7a2440fd487d8143e92aa2b7ae61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a1d7512e03f74f7798c9d335efb562a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "<center>\n<img src=https://huggingface.co/front/assets/huggingface_logo-noborder.svg alt='Hugging Face'>\n<br>\nCopy a token from <a href=\"https://huggingface.co/settings/token\" target=\"_blank\">your Hugging Face tokens page</a> and paste it below.\n<br>\nImmediately click login after copying your token or it might be stored in plain text in this notebook file.\n</center>",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a96b39391f94c8a82c209b6f1c2b53d"
          }
        },
        "31ab667aefa045c3b1ff00261b801672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "PasswordView",
            "style": "IPY_MODEL_11c97861f31e44c285abb27a5fb962b2",
            "_dom_classes": [],
            "description": "Token:",
            "_model_name": "PasswordModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66d238e972f34db88e4aff730282a5b4"
          }
        },
        "42d64507625d41fd95086e340425d69a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ButtonView",
            "style": "IPY_MODEL_d3f1afbcaeff415aa9067e6787e21262",
            "_dom_classes": [],
            "description": "Login",
            "_model_name": "ButtonModel",
            "button_style": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "tooltip": "",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "layout": "IPY_MODEL_b68bab8ce00042f1856c59c8a8acff9e",
            "_model_module": "@jupyter-widgets/controls",
            "icon": ""
          }
        },
        "4dcec957b10b406d9a2ee305b9cce738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f9fb376540c74fe29541ce953b2b7081",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated 'notebooks' token with 'write' access, that you can then easily reuse for all notebooks.\n<br>\n<i>Logging in with your username and password is deprecated and won't be possible anymore in the near future. You can still use them for now by clicking below.</i>\n</center>",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_158e936416a2495aa5cfb0e593155e54"
          }
        },
        "92709468e7164425967362ce666e63fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ButtonView",
            "style": "IPY_MODEL_28aad1c0dba3480389843dc364b8cfc4",
            "_dom_classes": [],
            "description": "Use password",
            "_model_name": "ButtonModel",
            "button_style": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "tooltip": "",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "layout": "IPY_MODEL_d7b3cb2d8d2944028859023b9326e02f",
            "_model_module": "@jupyter-widgets/controls",
            "icon": ""
          }
        },
        "a1d7512e03f74f7798c9d335efb562a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a96b39391f94c8a82c209b6f1c2b53d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11c97861f31e44c285abb27a5fb962b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66d238e972f34db88e4aff730282a5b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3f1afbcaeff415aa9067e6787e21262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ButtonStyleModel",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "button_color": null,
            "font_weight": "",
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b68bab8ce00042f1856c59c8a8acff9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9fb376540c74fe29541ce953b2b7081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "158e936416a2495aa5cfb0e593155e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28aad1c0dba3480389843dc364b8cfc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ButtonStyleModel",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "button_color": null,
            "font_weight": "",
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7b3cb2d8d2944028859023b9326e02f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf50bc4190b94a21aea94f2c19bdd023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a0d4f5d44d224c929d0be260e0ca5151",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_52df6d0202484dbd9a55717c12d09b44",
              "IPY_MODEL_3234bee7447848f59229bd1392d8dba6",
              "IPY_MODEL_6bc4d5719a674ec78e7ec3af21b12c2e"
            ]
          }
        },
        "a0d4f5d44d224c929d0be260e0ca5151": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "52df6d0202484dbd9a55717c12d09b44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50665e6d5bcc45c7a8c3ea58a5a4af21",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validation sanity check: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_860c47baa44845c1ac315ea623ab36fb"
          }
        },
        "3234bee7447848f59229bd1392d8dba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1dbca1e50fa14a92b29dfa4abc9eb8cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e131534c45d54723b871225b9785daf7"
          }
        },
        "6bc4d5719a674ec78e7ec3af21b12c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c1cc5159e7b4ca1b88ae5879c3edaa9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:00&lt;00:00,  2.01it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2056e6f329904e42a4c82691dfdace38"
          }
        },
        "50665e6d5bcc45c7a8c3ea58a5a4af21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "860c47baa44845c1ac315ea623ab36fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1dbca1e50fa14a92b29dfa4abc9eb8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e131534c45d54723b871225b9785daf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c1cc5159e7b4ca1b88ae5879c3edaa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2056e6f329904e42a4c82691dfdace38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f43cff606814637bb70a74e22b22ce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b15753e3ebf24cf1b09eba1c331d613c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_707a090cfcbf4ba588033c3e54de7a34",
              "IPY_MODEL_2a29c29f98684c27821b11a1ba999cd2",
              "IPY_MODEL_004cc4dd6e4a4564b26b0f71323fc664"
            ]
          }
        },
        "b15753e3ebf24cf1b09eba1c331d613c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "707a090cfcbf4ba588033c3e54de7a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9a2d340f7fa24bafa41d81d7241d9f56",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Epoch 0:  22%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68b7b8c6481c4841b40a67de3105bd68"
          }
        },
        "2a29c29f98684c27821b11a1ba999cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6387035d863749559293b535412c5bff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 6256,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1360,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6498ae933d24428b8361b37c6f6e44ab"
          }
        },
        "004cc4dd6e4a4564b26b0f71323fc664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_641afd6aeadf4f2ebbe56c35fb95b864",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1360/6256 [07:59&lt;28:45,  2.84it/s, loss=0.467, v_num=1]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32ec14afd6dd4bc983ec6f9b4e4105c7"
          }
        },
        "9a2d340f7fa24bafa41d81d7241d9f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68b7b8c6481c4841b40a67de3105bd68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6387035d863749559293b535412c5bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6498ae933d24428b8361b37c6f6e44ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "641afd6aeadf4f2ebbe56c35fb95b864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32ec14afd6dd4bc983ec6f9b4e4105c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}