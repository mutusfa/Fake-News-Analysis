{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DoSp_U0H28V4",
    "outputId": "80ee1fdb-6073-4e99-9ecd-236ac92ba824"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearnex import patch_sklearn\n",
    "\n",
    "patch_sklearn()\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchmetrics.functional import auroc\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "from jjuoda_dl4 import utils\n",
    "from jjuoda_dl4.utils import BASE_DATA_DIR, BASE_MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "20EOiwzK28V-"
   },
   "outputs": [],
   "source": [
    "nela_gt_2018_articles_df = pd.read_csv(\n",
    "    BASE_DATA_DIR / \"interim/nela-gt-2018-articles-with-text.csv\", index_col=0\n",
    ")\n",
    "nela_gt_2018_scores_df = pd.read_csv(\n",
    "    BASE_DATA_DIR / \"interim/nela-gt-2018-scores.csv\", index_col=0\n",
    ")\n",
    "nela_gt_2018_articles_df.dropna(subset=[\"title\", \"text\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6Z5XTcP28WA"
   },
   "source": [
    "### AutoNLP from HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "su-s2Y6O28WB"
   },
   "source": [
    "#### DataModules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LH-Z_dr828WB"
   },
   "outputs": [],
   "source": [
    "# I tried using hugging face api, my machine runs out of ram, so we'll use pytorch lightning\n",
    "\n",
    "\n",
    "class AutoNLPNELADataset(Dataset):\n",
    "    \"\"\"Recreates processeing I did for AutoNLP on nela gt 2018 data.\"\"\"\n",
    "\n",
    "    def __init__(self, articles_df, tokenizer, root_dir=BASE_DATA_DIR):\n",
    "        self.articles_df = articles_df\n",
    "        self.root_dir = root_dir\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.articles_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        article = self.articles_df.iloc[index]\n",
    "        with open(self.root_dir / article.path, \"r\") as f:\n",
    "            text = f.read().replace(\"\\n\", \" \")\n",
    "        text = \"<TITLE> \" + article.title + \" </TITLE> \" + text\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=\"longest_first\",\n",
    "        )\n",
    "        return {\n",
    "            \"model_inputs\": inputs,\n",
    "            \"source_score\": article.source_score,\n",
    "            \"is_fake\": article.source_score < 0,\n",
    "        }\n",
    "\n",
    "\n",
    "class AutoNLPNelaDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        articles_df,\n",
    "        tokenizer,\n",
    "        root_dir=BASE_DATA_DIR,\n",
    "        batch_size=32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.articles_df = articles_df\n",
    "        self.root_dir = root_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.train_dataset = AutoNLPNELADataset(\n",
    "            self.articles_df[self.articles_df.split == \"train\"],\n",
    "            self.tokenizer,\n",
    "            self.root_dir,\n",
    "        )\n",
    "        self.val_dataset = AutoNLPNELADataset(\n",
    "            self.articles_df[self.articles_df.split == \"val\"],\n",
    "            self.tokenizer,\n",
    "            self.root_dir,\n",
    "        )\n",
    "        self.test_dataset = AutoNLPNELADataset(\n",
    "            self.articles_df[self.articles_df.split == \"test\"],\n",
    "            self.tokenizer,\n",
    "            self.root_dir,\n",
    "        )\n",
    "        self.pred_dataset = AutoNLPNELADataset(\n",
    "            self.articles_df[self.articles_df.split == \"pred\"],\n",
    "            self.tokenizer,\n",
    "            self.root_dir,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4\n",
    "        )\n",
    "\n",
    "    def pred_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.pred_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SaWmuqZ28WE"
   },
   "source": [
    "I just hope to get quick results that I can look at and refine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387,
     "referenced_widgets": [
      "fd04ed39cfab41c0894795cb5fb628ca",
      "9686f94ee4ef4e8fa80ea72b7dee69b2",
      "cd7c7a2440fd487d8143e92aa2b7ae61",
      "31ab667aefa045c3b1ff00261b801672",
      "42d64507625d41fd95086e340425d69a",
      "4dcec957b10b406d9a2ee305b9cce738",
      "92709468e7164425967362ce666e63fc",
      "a1d7512e03f74f7798c9d335efb562a9",
      "4a96b39391f94c8a82c209b6f1c2b53d",
      "11c97861f31e44c285abb27a5fb962b2",
      "66d238e972f34db88e4aff730282a5b4",
      "d3f1afbcaeff415aa9067e6787e21262",
      "b68bab8ce00042f1856c59c8a8acff9e",
      "f9fb376540c74fe29541ce953b2b7081",
      "158e936416a2495aa5cfb0e593155e54",
      "28aad1c0dba3480389843dc364b8cfc4",
      "d7b3cb2d8d2944028859023b9326e02f"
     ]
    },
    "id": "iC8mVOIG28WE",
    "outputId": "67768c42-b2d6-432c-cb27-96d66c7ac373"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb5f153748649c39852c32ba45e9752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center>\\n<img src=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nShU4Y4U28WF"
   },
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"mutusfa/autonlp-Fake_News_Analysis-528914957\",\n",
    "    \"mutusfa/autonlp-Fake_News_Analysis-528914958\",\n",
    "    \"mutusfa/autonlp-Fake_News_Analysis-528914959\",\n",
    "    \"mutusfa/autonlp-Fake_News_Analysis-528914960\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qNdb_3PG28WG"
   },
   "outputs": [],
   "source": [
    "y = np.random.randn(1000)\n",
    "x = np.random.randint(0, 10, size=(1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "r2iJiiDw28WG"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def plot_predictions(articles_df, model_name):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, use_auth_token=True\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    data_module = AutoNLPNelaDataModule(articles_df, tokenizer, batch_size=64)\n",
    "    data_module.prepare_data()\n",
    "    dataloaders = [data_module.pred_dataloader()]\n",
    "\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    source_scores = []\n",
    "    with torch.no_grad():\n",
    "        for dataloader in dataloaders:\n",
    "            for batch in dataloader:\n",
    "                # I'm not sure why do I get 32 * 1 * 512 tensors\n",
    "                for k in batch[\"model_inputs\"]:\n",
    "                    batch[\"model_inputs\"][k] = (\n",
    "                        batch[\"model_inputs\"][k].squeeze(1).to(device)\n",
    "                    )\n",
    "                preds.extend(\n",
    "                    sigmoid(model(**batch[\"model_inputs\"]).logits[:, 1].cpu().numpy())\n",
    "                )\n",
    "                source_scores.extend(batch[\"source_score\"].numpy())\n",
    "\n",
    "    plt.figure()\n",
    "    ax = sns.regplot(\n",
    "        x=source_scores,\n",
    "        y=preds,\n",
    "        x_jitter=0.1,\n",
    "        line_kws={\"color\": \"#859900\"},\n",
    "        scatter_kws={\"alpha\": 0.5},\n",
    "    )\n",
    "    plt.suptitle(model_name)\n",
    "    plt.ylabel(\"Predicted probability of being fake\")\n",
    "    plt.xlabel(\"Source score\")\n",
    "    plt.savefig(\n",
    "        BASE_DATA_DIR / f\"processed/{model_name.replace('/', '_')}_reg_predictions.png\"\n",
    "    )\n",
    "\n",
    "    return preds, source_scores\n",
    "\n",
    "\n",
    "# for model_name in model_names:\n",
    "#     preds, scores = plot_predictions(\n",
    "#         nela_gt_2018_articles_df[nela_gt_2018_articles_df.split == \"pred\"].sample(\n",
    "#             n=1000, random_state=42\n",
    "#         ),\n",
    "#         model_name,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xPZUg5r28WH"
   },
   "source": [
    "These models achieved much better auc than knn models (all above .95 versus .86 I had with knn) on their validation set. The only problem - training set was quite imbalanced and I have changed both training set and validation set, so they are not directly comparable.\n",
    "\n",
    "Looking at the data both models didn't see, we see interesting differences.\n",
    "1. KNNs predict most news as having high probability of being fake news, while AutoNLP models predict most news as having low probability of being fake news.\n",
    "1. It also seems that AutoNLP models generalize pretty badly - some can't distinguish between sources with -1 score and sources with 1 score. I guess I have to check if I can distinguish that, but knns seem to be able to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iq2UQZCw28WH"
   },
   "source": [
    "Let's try tuning a few models and see if I can get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMXWfhQW28WH"
   },
   "source": [
    "### My work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AAFa3Odq28WH"
   },
   "outputs": [],
   "source": [
    "class NELADataset(Dataset):\n",
    "    def __init__(self, articles_df, tokenizer, root_dir=BASE_DATA_DIR):\n",
    "        self.articles_df = articles_df\n",
    "        self.root_dir = root_dir\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.articles_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        article = self.articles_df.iloc[index]\n",
    "        if \"text\" in article.keys():\n",
    "            text = article[\"text\"]\n",
    "        else:\n",
    "            with open(self.root_dir / article.path, \"r\") as f:\n",
    "                text = f.read()\n",
    "        inputs = self.tokenizer(\n",
    "            article.title,\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=\"longest_first\",\n",
    "            # max_length=256,\n",
    "        )\n",
    "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n",
    "        inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n",
    "        return inputs\n",
    "\n",
    "\n",
    "class NelaDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        articles_df,\n",
    "        tokenizer,\n",
    "        root_dir=BASE_DATA_DIR,\n",
    "        batch_size=8,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.articles_df = articles_df\n",
    "        self.root_dir = root_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.sample_weights: np.array = None\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.train_dataset = NELADataset(\n",
    "            self.articles_df[self.articles_df.split == \"train\"],\n",
    "            self.tokenizer,\n",
    "            self.root_dir,\n",
    "        )\n",
    "        # calculate sample weights to balance classes;\n",
    "        # they are not normalized, since torch samplers don't need them to be normalized\n",
    "        self.sample_weights = np.ones(len(self.train_dataset))\n",
    "        num_fake = np.sum(self.train_dataset.articles_df.is_fake)\n",
    "        self.sample_weights[self.train_dataset.articles_df.is_fake] /= num_fake\n",
    "        self.sample_weights[~self.train_dataset.articles_df.is_fake] /= (\n",
    "            len(self.sample_weights) - num_fake\n",
    "        )\n",
    "\n",
    "        self.val_dataset = NELADataset(\n",
    "            self.articles_df[self.articles_df.split == \"val\"],\n",
    "            self.tokenizer,\n",
    "            self.root_dir,\n",
    "        )\n",
    "        self.test_dataset = NELADataset(\n",
    "            self.articles_df[self.articles_df.split == \"test\"],\n",
    "            self.tokenizer,\n",
    "            self.root_dir,\n",
    "        )\n",
    "        self.pred_dataset = NELADataset(\n",
    "            self.articles_df[self.articles_df.split == \"pred\"],\n",
    "            self.tokenizer,\n",
    "            self.root_dir,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            sampler=WeightedRandomSampler(\n",
    "                self.sample_weights, len(self.sample_weights)\n",
    "            ),\n",
    "            num_workers=2,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2\n",
    "        )\n",
    "\n",
    "    def pred_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.pred_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2fSZ4JL28WI",
    "outputId": "1f0f4cd5-1c01-4d38-c9b4-adea8a5bf0ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.DistilBertTokenizerFast.from_pretrained(\n",
    "    \"distilbert-base-uncased\"\n",
    ")\n",
    "model = transformers.DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yoq4QylY28WI"
   },
   "outputs": [],
   "source": [
    "nela_gt_2018_data_module = NelaDataModule(nela_gt_2018_articles_df, tokenizer)\n",
    "nela_gt_2018_data_module.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jkzRQD4U28WJ"
   },
   "outputs": [],
   "source": [
    "class NelaModel(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def backbone_grad(self, value):\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = value\n",
    "        for param in self.model.pre_classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, **model_inputs):\n",
    "        return self.model(**model_inputs)\n",
    "\n",
    "    def _shared_step(self, batch, batch_idx):\n",
    "        return self.model(**batch)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        results = self._shared_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", results.loss.detach())\n",
    "        return results\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        results = self._shared_step(batch, batch_idx)\n",
    "        self.log(\"val_loss\", results.loss.detach())\n",
    "        self.log(\n",
    "            \"val_auc\",\n",
    "            auroc(\n",
    "                torch.sigmoid(results.logits.detach()[:, 1]),\n",
    "                batch[\"labels\"],\n",
    "                num_classes=2,\n",
    "            ),\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            params=[p for p in self.parameters() if p.requires_grad],\n",
    "            lr=self.learning_rate,\n",
    "        )\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2)\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }\n",
    "\n",
    "\n",
    "nela_model = NelaModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449,
     "referenced_widgets": [
      "bf50bc4190b94a21aea94f2c19bdd023",
      "a0d4f5d44d224c929d0be260e0ca5151",
      "52df6d0202484dbd9a55717c12d09b44",
      "3234bee7447848f59229bd1392d8dba6",
      "6bc4d5719a674ec78e7ec3af21b12c2e",
      "50665e6d5bcc45c7a8c3ea58a5a4af21",
      "860c47baa44845c1ac315ea623ab36fb",
      "1dbca1e50fa14a92b29dfa4abc9eb8cd",
      "e131534c45d54723b871225b9785daf7",
      "6c1cc5159e7b4ca1b88ae5879c3edaa9",
      "2056e6f329904e42a4c82691dfdace38",
      "3f43cff606814637bb70a74e22b22ce2",
      "b15753e3ebf24cf1b09eba1c331d613c",
      "707a090cfcbf4ba588033c3e54de7a34",
      "2a29c29f98684c27821b11a1ba999cd2",
      "004cc4dd6e4a4564b26b0f71323fc664",
      "9a2d340f7fa24bafa41d81d7241d9f56",
      "68b7b8c6481c4841b40a67de3105bd68",
      "6387035d863749559293b535412c5bff",
      "6498ae933d24428b8361b37c6f6e44ab",
      "641afd6aeadf4f2ebbe56c35fb95b864",
      "32ec14afd6dd4bc983ec6f9b4e4105c7"
     ]
    },
    "id": "tzmf7Vrt28WJ",
    "outputId": "9152b93c-980b-4216-caf9-2890261db618"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "nela_model.backbone_grad(False)\n",
    "nela_model.learning_rate = 1e-3\n",
    "trainer = pl.Trainer(\n",
    "    min_epochs=3,\n",
    "    gpus=1,\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(patience=5, min_delta=0.0001, monitor=\"val_loss\"),\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval=\"step\", log_momentum=False),\n",
    "        pl.callbacks.model_checkpoint.ModelCheckpoint(\n",
    "            BASE_MODEL_DIR / \"best\",\n",
    "            filename=\"{epoch}-{val_loss:.2f}-{val_auc:.2f}\",\n",
    "            monitor=\"val_loss\",\n",
    "        ),\n",
    "    ],\n",
    "    default_root_dir=BASE_MODEL_DIR,\n",
    ")\n",
    "# trainer.fit(nela_model, nela_gt_2018_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RH6Z5eD39WuU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                                | Params\n",
      "--------------------------------------------------------------\n",
      "0 | model | DistilBertForSequenceClassification | 67.0 M\n",
      "--------------------------------------------------------------\n",
      "67.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "67.0 M    Total params\n",
      "267.820   Total estimated model params size (MB)\n",
      "/home/julius/.conda/envs/jjuoda-DL.4/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/julius/lp/Turing/jjuoda-DL.4/models/best exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/.conda/envs/jjuoda-DL.4/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n",
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/.conda/envs/jjuoda-DL.4/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/julius/.conda/envs/jjuoda-DL.4/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/25024 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n",
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n",
      "/home/julius/.conda/envs/jjuoda-DL.4/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/closure.py:35: LightningDeprecationWarning: One of the returned values {'logits'} has a `grad_fn`. We will detach it automatically but this behaviour will change in v1.6. Please detach it manually: `return {'loss': ..., 'something': something.detach()}`\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  94%|█████████▍| 23520/25024 [2:54:13<11:08,  2.25it/s, loss=0.162, v_num=6]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n",
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  94%|█████████▍| 23532/25024 [2:54:15<11:02,  2.25it/s, loss=0.162, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/.conda/envs/jjuoda-DL.4/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/25024 [00:00<?, ?it/s, loss=0.162, v_num=6]              "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n",
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  94%|█████████▍| 23520/25024 [2:55:58<11:15,  2.23it/s, loss=0.0407, v_num=6]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n",
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 0/25024 [00:00<?, ?it/s, loss=0.0407, v_num=6]              "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n",
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  94%|█████████▍| 23520/25024 [3:01:36<11:36,  2.16it/s, loss=0.014, v_num=6]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n",
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 0/25024 [00:00<?, ?it/s, loss=0.014, v_num=6]              "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n",
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  94%|█████████▍| 23520/25024 [3:13:11<12:21,  2.03it/s, loss=0.0317, v_num=6]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n",
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 0/25024 [00:00<?, ?it/s, loss=0.0317, v_num=6]              "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n",
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  94%|█████████▍| 23520/25024 [3:05:00<11:49,  2.12it/s, loss=0.00119, v_num=6]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n",
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:   0%|          | 0/25024 [00:00<?, ?it/s, loss=0.00119, v_num=6]              "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n",
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  94%|█████████▍| 23520/25024 [3:03:19<11:43,  2.14it/s, loss=0.000741, v_num=6]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n",
      "/tmp/ipykernel_6119/3489036898.py:27: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  inputs[\"labels\"] = torch.tensor(article.is_fake, dtype=int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 25024/25024 [3:07:29<00:00,  2.22it/s, loss=0.000741, v_num=6]\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\n",
    "    BASE_MODEL_DIR / \"best\" / \"epoch=3-val_loss=0.59-val_auc=0.20.ckpt\"\n",
    ")\n",
    "nela_model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "nela_model.backbone_grad(True)\n",
    "nela_model.learning_rate = 1e-5\n",
    "trainer = pl.Trainer(\n",
    "    min_epochs=3,\n",
    "    gpus=1,\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(patience=5, min_delta=0.0001, monitor=\"val_loss\"),\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval=\"step\", log_momentum=False),\n",
    "        pl.callbacks.model_checkpoint.ModelCheckpoint(\n",
    "            BASE_MODEL_DIR / \"best\",\n",
    "            filename=\"{epoch}-{val_loss:.2f}-{val_auc:.2f}\",\n",
    "            monitor=\"val_loss\",\n",
    "        ),\n",
    "    ],\n",
    "    default_root_dir=BASE_MODEL_DIR,\n",
    ")\n",
    "trainer.fit(nela_model, nela_gt_2018_data_module)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "deep_learning.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "5a7d5478afe2248c49abfa1219649289765da77ad68068bfc5af38a5747c85f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "004cc4dd6e4a4564b26b0f71323fc664": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32ec14afd6dd4bc983ec6f9b4e4105c7",
      "placeholder": "​",
      "style": "IPY_MODEL_641afd6aeadf4f2ebbe56c35fb95b864",
      "value": " 1360/6256 [07:59&lt;28:45,  2.84it/s, loss=0.467, v_num=1]"
     }
    },
    "11c97861f31e44c285abb27a5fb962b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "158e936416a2495aa5cfb0e593155e54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1dbca1e50fa14a92b29dfa4abc9eb8cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2056e6f329904e42a4c82691dfdace38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28aad1c0dba3480389843dc364b8cfc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "2a29c29f98684c27821b11a1ba999cd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6498ae933d24428b8361b37c6f6e44ab",
      "max": 6256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6387035d863749559293b535412c5bff",
      "value": 1360
     }
    },
    "31ab667aefa045c3b1ff00261b801672": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_66d238e972f34db88e4aff730282a5b4",
      "placeholder": "​",
      "style": "IPY_MODEL_11c97861f31e44c285abb27a5fb962b2",
      "value": ""
     }
    },
    "3234bee7447848f59229bd1392d8dba6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e131534c45d54723b871225b9785daf7",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1dbca1e50fa14a92b29dfa4abc9eb8cd",
      "value": 2
     }
    },
    "32ec14afd6dd4bc983ec6f9b4e4105c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f43cff606814637bb70a74e22b22ce2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_707a090cfcbf4ba588033c3e54de7a34",
       "IPY_MODEL_2a29c29f98684c27821b11a1ba999cd2",
       "IPY_MODEL_004cc4dd6e4a4564b26b0f71323fc664"
      ],
      "layout": "IPY_MODEL_b15753e3ebf24cf1b09eba1c331d613c"
     }
    },
    "42d64507625d41fd95086e340425d69a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_b68bab8ce00042f1856c59c8a8acff9e",
      "style": "IPY_MODEL_d3f1afbcaeff415aa9067e6787e21262",
      "tooltip": ""
     }
    },
    "4a96b39391f94c8a82c209b6f1c2b53d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4dcec957b10b406d9a2ee305b9cce738": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_158e936416a2495aa5cfb0e593155e54",
      "placeholder": "​",
      "style": "IPY_MODEL_f9fb376540c74fe29541ce953b2b7081",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated 'notebooks' token with 'write' access, that you can then easily reuse for all notebooks.\n<br>\n<i>Logging in with your username and password is deprecated and won't be possible anymore in the near future. You can still use them for now by clicking below.</i>\n</center>"
     }
    },
    "50665e6d5bcc45c7a8c3ea58a5a4af21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "52df6d0202484dbd9a55717c12d09b44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_860c47baa44845c1ac315ea623ab36fb",
      "placeholder": "​",
      "style": "IPY_MODEL_50665e6d5bcc45c7a8c3ea58a5a4af21",
      "value": "Validation sanity check: 100%"
     }
    },
    "6387035d863749559293b535412c5bff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "641afd6aeadf4f2ebbe56c35fb95b864": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6498ae933d24428b8361b37c6f6e44ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66d238e972f34db88e4aff730282a5b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68b7b8c6481c4841b40a67de3105bd68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bc4d5719a674ec78e7ec3af21b12c2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2056e6f329904e42a4c82691dfdace38",
      "placeholder": "​",
      "style": "IPY_MODEL_6c1cc5159e7b4ca1b88ae5879c3edaa9",
      "value": " 2/2 [00:00&lt;00:00,  2.01it/s]"
     }
    },
    "6c1cc5159e7b4ca1b88ae5879c3edaa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "707a090cfcbf4ba588033c3e54de7a34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68b7b8c6481c4841b40a67de3105bd68",
      "placeholder": "​",
      "style": "IPY_MODEL_9a2d340f7fa24bafa41d81d7241d9f56",
      "value": "Epoch 0:  22%"
     }
    },
    "860c47baa44845c1ac315ea623ab36fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92709468e7164425967362ce666e63fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Use password",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_d7b3cb2d8d2944028859023b9326e02f",
      "style": "IPY_MODEL_28aad1c0dba3480389843dc364b8cfc4",
      "tooltip": ""
     }
    },
    "9686f94ee4ef4e8fa80ea72b7dee69b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "9a2d340f7fa24bafa41d81d7241d9f56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0d4f5d44d224c929d0be260e0ca5151": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "a1d7512e03f74f7798c9d335efb562a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b15753e3ebf24cf1b09eba1c331d613c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "b68bab8ce00042f1856c59c8a8acff9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf50bc4190b94a21aea94f2c19bdd023": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_52df6d0202484dbd9a55717c12d09b44",
       "IPY_MODEL_3234bee7447848f59229bd1392d8dba6",
       "IPY_MODEL_6bc4d5719a674ec78e7ec3af21b12c2e"
      ],
      "layout": "IPY_MODEL_a0d4f5d44d224c929d0be260e0ca5151"
     }
    },
    "cd7c7a2440fd487d8143e92aa2b7ae61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a96b39391f94c8a82c209b6f1c2b53d",
      "placeholder": "​",
      "style": "IPY_MODEL_a1d7512e03f74f7798c9d335efb562a9",
      "value": "<center>\n<img src=https://huggingface.co/front/assets/huggingface_logo-noborder.svg alt='Hugging Face'>\n<br>\nCopy a token from <a href=\"https://huggingface.co/settings/token\" target=\"_blank\">your Hugging Face tokens page</a> and paste it below.\n<br>\nImmediately click login after copying your token or it might be stored in plain text in this notebook file.\n</center>"
     }
    },
    "d3f1afbcaeff415aa9067e6787e21262": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "d7b3cb2d8d2944028859023b9326e02f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e131534c45d54723b871225b9785daf7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9fb376540c74fe29541ce953b2b7081": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd04ed39cfab41c0894795cb5fb628ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cd7c7a2440fd487d8143e92aa2b7ae61",
       "IPY_MODEL_31ab667aefa045c3b1ff00261b801672",
       "IPY_MODEL_42d64507625d41fd95086e340425d69a",
       "IPY_MODEL_4dcec957b10b406d9a2ee305b9cce738",
       "IPY_MODEL_92709468e7164425967362ce666e63fc"
      ],
      "layout": "IPY_MODEL_9686f94ee4ef4e8fa80ea72b7dee69b2"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
